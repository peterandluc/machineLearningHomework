%
% File ACL2016.tex
%
\documentclass[11pt]{article}
\usepackage{fss2017seminar}
\usepackage{times}
\usepackage{latexsym}

\aclfinalcopy % Uncomment this line for the final submission

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

\newcommand\BibTeX{B{\sc ib}\TeX}


\title{Seminar: Generating Narrative Paragraph for Photo Stream via Bidirectional Attention Recurrent Neural Networks}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
\author{Chen Zongqi\\
	    Matriculation Number 1564832\\
	    University of Mannheim, Germany\\
	    {\tt zchen@mail.uni-mannheim.de}}

\date{}

\begin{document}

\maketitle

	\begin{abstract}
	When machine learning techniques develop rapidly in image captioning, other extension relevant areas appeal to many researchers doing further study. Among them generating story from sequential photo stream becomes quite interesting and challenging task. Compared with single image captioning, this task needs to handle with two mainly problems facing to researchers, large visual variance in sequence and longterm language coherence among multiple sentences. Till now those two critical questions are solved by different approaches. In this paper, we mainly focus on one of them, generating story from sequential photos stream via Bidirectional Attention Recurrent Neural Network method, and discus several relevant approaches from first paper to state-of-the-art.   
	\end{abstract}

	\section{Introduction}
	


	\section{Related Work}
	
	Due to interaction between computer vision and natural language processing is new topic, particularly in image description, there are several researches divided in three categories: single-frame to single-sentence, multi-frame to single-sentence and multi-frame to multi-sentence.		
		
		\subsection{ Single-frame to single-sentence}
		These researches focus on image captioning task, which can be classified into two sub-categories: semantic element based methods

		\subsection{Multi-frame to single-sentence}
		This family of approaches, mainly focus on video captioning to captures the temporal dynamics in variable-length of video frames sequence and to map them to a variable-length of words.		
		
		
		\subsection{Multi-frame to multi-sentence}
		The work by is the first scheme to explore the task of image streams to sentence sequence.		
		
		
	\section{Approach}
		\subsection{Joint Embedding for Semantic Space}
		
		\subsection{Bidirectional Attention RNN for Textual Story Generation}
		
	\section{Experiment}
	

	\section{Evaluation}


	\section{Discussion}
		aaaaa \cite{Chandra:81}

	\bibliography{bibliography}
	\bibliographystyle{fss2017seminar}

\end{document}
